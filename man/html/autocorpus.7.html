<!-- manual page source format generated by PolyglotMan v3.2, -->
<!-- available at http://polyglotman.sourceforge.net/ -->

<html>
<head>
<title>ngrams(5) manual page</title>
</head>
<body bgcolor='white'>
<a href='#toc'>Table of Contents</a><p>

<p> 
<h2><a name='sect0' href='#toc0'>Introduction</a></h2>
Autocorpus is a set of utilities that enable automatic extraction
of language corpora and language models from publicly available datasets.
For example, it provides the full set of tools to translate the entire
English Wikipedia from a 30+GB XML file to a clean n-gram language model,
all in a matter of a few hours. 
<p> This document describes how to accomplish
common tasks using the Autocorpus tools. 
<p> 
<h2><a name='sect1' href='#toc1'>Plaintext Wikipedia</a></h2>
Autocorpus
includes two tools that enable extraction and conversion to plaintext of
Wikipedia articles: <b>wiki-articles</b> and <b>wiki-textify.</b> 
<p> <b>wiki-articles </b> reads Wikipedia
XML databases (http://dumps.wikimedia.org/enwiki/) and extracts article markup.
The extracted markup is written to standard output, with articles delimited
by page feeds \f. 
<p> <b>wiki-textify</b> reads the output produced by <b>wiki-articles</b>
and removes MediaWiki markup. The result is a plaintext version of Wikipedia
articles. 
<p> The two programs are intended to be used in a pipeline. For example,
if you have the June 2011 Wikipedia database you can convert it to plaintext
as follows: <br>
<pre>pv enwiki-20110620-pages-articles.xml | wiki-articles | wiki-textify -h &gt; \
wikipedia-plaintext.txt
</pre>
<p> The output will then be saved in the file  <i>wikipedia-plaintext.txt</i> (if 
<b>pv</b> is not available on your system, you can use  <b>cat</b> instead). 
<p> The optional
flag <b>-h</b> suppresses section headings in the output. 
<p> 
<h2><a name='sect2' href='#toc2'>Cleaning Up Text</a></h2>
Autocorpus
includes utilities for cleaning up text:  <b>sentences</b> and <b>tokenize</b>. 
<p> <b>sentences</b>
splits its input into separate sentences, one per output line.  It also
splits paragraphs by inserting an extra linebreak between the last and
first sentences of consecutive paragraphs. 
<p> <b>tokenize </b> normalizes words within
sentences by downcasing all characters and making sure words are separated
by exactly one space. By default it also ignores text within parentheses.

<p> For example, to clean up the text file <i>wikipedia-plaintext.txt</i>  and save
it as  <i>wikipedia-clean.txt</i>, pipe it through both  <b>sentences </b> and <b>tokenize</b>:
<br>
<pre>pv wikipedia-plaintext.txt | sentences | tokenize &gt; \
wikipedia-clean.txt
</pre>
<p> 
<h2><a name='sect3' href='#toc3'>Counting Ngrams</a></h2>

<p> To count ngrams in a text file, clean it up first (see
section above) and then pipe it to the <b>ngrams</b> utility. For example, the
command below will count bigrams in the file <i>wikipedia-clean.txt</i> and save
the result in <i>bigrams.txt</i>: <br>
<pre>pv wikipedia-clean.txt | ngrams -n 2 &gt; bigrams.txt
</pre>
<p> The ngrams produced by the <b>ngrams</b> utility will appear in a random order.
To sort them by decreasing counts (most frequent ngrams first), pipe the
output of  <b>ngrams</b> to  <b>ngrams-sort</b>: <br>
<pre>pv wikipedia-clean.txt | ngrams -n 2 | ngrams-sort &gt; bigrams.txt
</pre>
<p> 
<h2><a name='sect4' href='#toc4'>Filtering Ngrams</a></h2>
<b>ngrams-freq-filter</b> lets you filter out ngrams with counts
below a specified threshold. This will allow you, among other things, to
remove some noise from your language model. 
<p> For example, to filter out
ngrams with counts below 5 in the file bigrams.txt, run: <br>
<pre>pv bigrams.txt | ngrams-freq-filter -t 5
</pre>
<p> 
<h2><a name='sect5' href='#toc5'>Limitations: Unicode</a></h2>
Currently, autocorpus only has a limited support for
unicode (UTF-8). While unicode input and output should mostly work, some
characters might not be decoded correctly. 
<p> If you encounter a Unicode issue
with any of the autocorpus utilities, an easy workaround is to use an ASCII
converter, e.g.   <b>uni2ascii</b>. 
<p> Before passing input data to autocorpus tools,
pipe it to  <b>uni2ascii</b> first and then convert it back to Unicode with  <b>ascii2uni
</b> when you&rsquo;re done. For example: <br>
<pre>pv enwiki-20110620-pages-articles.xml | uni2ascii | wiki-articles | \
wiki-textify -h | ascii2uni &gt; wikipedia-plaintext.txt
</pre>
<p> 
<h2><a name='sect6' href='#toc6'>Limitations: Non-English Languages</a></h2>
Current release of autocorpus was designed
for English corpora and your results with other languages may vary. In particular,
the <b>sentences</b> and <b>tokenize</b> utilities may have trouble breaking sentences
and cleaning up punctuation in languages other than English. 
<p> 
<h2><a name='sect7' href='#toc7'>Author</a></h2>
Autocorpus
was written by Maciej Pacula (maciej.pacula@gmail.com). 
<p> The project website

is <a href='http://mpacula.com/autocorpus'>http://mpacula.com/autocorpus</a>
 
<p> 
<h2><a name='sect8' href='#toc8'>See Also</a></h2>
<a href='ngrams.1.html'><b>ngrams</b>(1)</a>
, <a href='ngrams.5.html'><b>ngrams</b>(5)</a>
, <a href='ngrams-freq-filter.1.html'><b>ngrams-freq-filter</b>(1)</a>
,
<a href='ngrams-sort.1.html'><b>ngrams-sort</b>(1)</a>
, <a href='sentences.1.html'><b>sentences</b>(1)</a>
, <a href='tokenize.1.html'><b>tokenize</b>(1)</a>
, <a href='wiki-articles.1.html'><b>wiki-articles</b>(1)</a>
, <a href='wiki-textify.1.html'><b>wiki-textify</b>(1)</a>
,

<p> <p>

<hr><p>
<a name='toc'><b>Table of Contents</b></a><p>
<ul>
<li><a name='toc0' href='#sect0'>Introduction</a></li>
<li><a name='toc1' href='#sect1'>Plaintext Wikipedia</a></li>
<li><a name='toc2' href='#sect2'>Cleaning Up Text</a></li>
<li><a name='toc3' href='#sect3'>Counting Ngrams</a></li>
<li><a name='toc4' href='#sect4'>Filtering Ngrams</a></li>
<li><a name='toc5' href='#sect5'>Limitations: Unicode</a></li>
<li><a name='toc6' href='#sect6'>Limitations: Non-English Languages</a></li>
<li><a name='toc7' href='#sect7'>Author</a></li>
<li><a name='toc8' href='#sect8'>See Also</a></li>
</ul>
</body>
</html>
